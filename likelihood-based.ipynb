{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import permutations\n",
    "from copy import deepcopy\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "def ScBM_generator(row_label, column_label, link_matrices, density=1):\n",
    "    \"\"\"Returns a multi-layer stochastic co-blockmodel graph (L*Ky*Kz). see also nx.stochastic_block_model\"\"\"\n",
    "    p_matrices = link_matrices[:,row_label][:,:,column_label]\n",
    "    p_matrices = p_matrices - np.einsum('jk,ik->jki', np.diagonal(p_matrices, axis1=1, axis2=2), np.eye(p_matrices.shape[2])) \n",
    "    return np.random.binomial(1, density*p_matrices)\n",
    "\n",
    "\n",
    "def k_eigenvectors(scbm, K, method, row=True):\n",
    "    \"\"\" Returns the K leading eigenvectors;  method: {\"sum\", \"qsum\"(include qsum_debias)} \"\"\"\n",
    "    # the sum of adjacency matrices\n",
    "    if method == \"sum\":\n",
    "        u, _, v = np.linalg.svd(np.sum(scbm, axis=0))\n",
    "        vs = u[:, 0:K] if row else v[0:K, ].T  # K leading eigenvectors\n",
    "        return vs\n",
    "\n",
    "    if method == \"qsum\": \n",
    "        if row:\n",
    "            square = np.zeros_like(scbm)\n",
    "            for l in range(scbm.shape[0]):\n",
    "                Al_sparse = sparse.coo_matrix(scbm[l])\n",
    "                square[l] = Al_sparse.dot(Al_sparse.T).toarray()\n",
    "\n",
    "            # the sum of squared adjacency matriecs\n",
    "            _, v = np.linalg.eigh(np.sum(square, axis=0))\n",
    "            vs = v[:, ::-1][:, 0:K]  # ascending order\n",
    "            # the bias-adjusted sum of squared adjacency matriecs\n",
    "            _, v = np.linalg.eigh(np.sum(square, axis=0) - np.diag(np.sum(scbm, axis=0).sum(axis=1)))\n",
    "            vs_debias = v[:, ::-1][:, 0:K]\n",
    "\n",
    "        else:\n",
    "            square = np.zeros_like(scbm)\n",
    "            for l in range(scbm.shape[0]):\n",
    "                Al_sparse = sparse.coo_matrix(scbm[l])\n",
    "                square[l] = Al_sparse.T.dot(Al_sparse).toarray()\n",
    "\n",
    "            _, u = np.linalg.eigh(np.sum(square, axis=0))\n",
    "            vs = u[:, ::-1][:, 0:K]\n",
    "            _, u = np.linalg.eigh(np.sum(square, axis=0) - np.diag(np.sum(scbm, axis=0).sum(axis=0)))\n",
    "            vs_debias = u[:, ::-1][:, 0:K]\n",
    "        return vs, vs_debias \n",
    "\n",
    "\n",
    "def block_sums(scbm, clusters_est, K_clusters):\n",
    "    \"\"\" block sums B \"\"\"\n",
    "    B = np.zeros((scbm.shape[0], scbm.shape[1], K_clusters))\n",
    "    for k in range(K_clusters):\n",
    "        mask = (clusters_est == k).reshape(1, 1, -1)\n",
    "        B[:, :, k] = (scbm * mask).sum(axis=2)\n",
    "    return B\n",
    "\n",
    "def initial_param(scbm, K_clusters, clusters_init):\n",
    "    masks = [(clusters_init == k).reshape(1, -1, 1) for k in range(K_clusters)]\n",
    "    obs = np.zeros((scbm.shape[0], K_clusters, K_clusters))\n",
    "    for i in range(K_clusters):\n",
    "        for j in range(K_clusters):\n",
    "            obs[:, i, j] = np.sum(scbm * masks[i] * masks[j].transpose(0, 2, 1), axis=(1, 2))\n",
    "    P_hat = obs / np.outer(np.bincount(clusters_init, minlength=K_clusters), np.bincount(clusters_init, minlength=K_clusters))\n",
    "\n",
    "    pi = np.bincount(clusters_init, minlength=K_clusters) / scbm.shape[1]\n",
    "    R_hat = np.diag(pi)\n",
    "    Lambda_hat = scbm.shape[1] * R_hat @ P_hat\n",
    "    return pi, P_hat, Lambda_hat.transpose((0, 2, 1))\n",
    "\n",
    "\n",
    "def PL(scbm, K_clusters, clusters_init, T=20, maxiter=1000, tol=1e-4, row=True):\n",
    "    if not row: scbm = scbm.transpose((0, 2, 1))\n",
    "    pi_hat, _, lambda_hat = initial_param(scbm, K_clusters, clusters_init)\n",
    "    r_est = clusters_init\n",
    "    for t in range(T):\n",
    "        B = block_sums(scbm, r_est, K_clusters)\n",
    "        inner_iter = 0\n",
    "        while inner_iter < maxiter:\n",
    "            # eq 9\n",
    "            lambda_hat = np.where(lambda_hat<=0, 1e-5, lambda_hat) # avoid log with a negative input\n",
    "            temp = B[:, :, np.newaxis, :] * np.log(lambda_hat[:, np.newaxis, :, :]) - lambda_hat[:, np.newaxis, :, :]\n",
    "            temp = np.sum(temp, axis=(0, 3)) - np.max(np.sum(temp, axis=(0, 3)), axis=1)[:, np.newaxis] # avoid overflow\n",
    "            temp = np.exp(temp) * pi_hat\n",
    "\n",
    "            # temp = np.exp(np.sum(temp, axis=(0, 3))) * pi_hat\n",
    "            pi_mat = temp / temp.sum(axis=1)[:, np.newaxis]\n",
    "            pi_hat_new = np.mean(pi_mat, axis=0)\n",
    "            temp = np.sum(pi_mat, axis=0)[:, np.newaxis]\n",
    "            temp = np.where(temp <= 0, 1e-5, temp)\n",
    "            lambda_hat_new = np.sum(pi_mat[np.newaxis, :, :, np.newaxis] * B[:, :, np.newaxis, :], axis=1) / temp\n",
    "            error_pi, error_lambda = np.linalg.norm(pi_hat_new - pi_hat), np.linalg.norm(lambda_hat_new - lambda_hat)\n",
    "            pi_hat, lambda_hat = pi_hat_new, lambda_hat_new\n",
    "            if max(error_pi, error_lambda) < tol:\n",
    "                break\n",
    "            inner_iter += 1\n",
    "        \n",
    "        # eq 12\n",
    "        r_est = np.argmax(pi_mat, axis=1)\n",
    "    return r_est\n",
    "\n",
    "def PPL(scbm, K_clusters, clusters_init, T=20, maxiter=200, tol=1e-3, row=True):\n",
    "    if row: scbm = scbm.transpose((0, 2, 1))\n",
    "    pi_hat, P_hat, _ = initial_param(scbm, K_clusters, clusters_init)\n",
    "    clusters_est = clusters_init\n",
    "    for t in range(T):\n",
    "        inner_iter = 0\n",
    "        while inner_iter < maxiter:\n",
    "            # E-step\n",
    "            P_hat = np.where(P_hat<=0, 1e-5, P_hat)\n",
    "            P_hat = np.where(P_hat>=1, 1 - 1e-5, P_hat)\n",
    "            P_temp = P_hat[:, :, clusters_est]\n",
    "            temp = scbm[:, :, np.newaxis, :] * np.log(P_temp[:, np.newaxis, :, :]) + (1 - scbm[:, :, np.newaxis, :]) * np.log(1 - P_temp[:, np.newaxis, :, :])\n",
    "            pi_hat = np.where(pi_hat<=0, 1e-5, pi_hat)\n",
    "            temp = np.exp(np.sum(temp, axis=(0, 3)) + np.log(pi_hat) - np.max(np.sum(temp, axis=(0, 3)) + np.log(pi_hat), axis=1)[:, np.newaxis])\n",
    "            tau_mat = temp / temp.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "            # M-step\n",
    "            pi_hat_new = np.mean(tau_mat, axis=0)\n",
    "            indicator = np.zeros((scbm.shape[1], K_clusters))\n",
    "            indicator[np.arange(scbm.shape[1]), clusters_est] = 1\n",
    "            temp_num = scbm[:, :, :, np.newaxis, np.newaxis] * tau_mat[np.newaxis, :, np.newaxis, :, np.newaxis] * indicator[np.newaxis, np.newaxis, :, np.newaxis, :]\n",
    "            temp_num = np.sum(temp_num, axis=(1, 2)) \n",
    "            temp_denom = tau_mat[:, np.newaxis, :, np.newaxis] * indicator[np.newaxis, :, np.newaxis, :]\n",
    "            temp_denom = np.sum(temp_denom, axis=(0, 1))\n",
    "            temp_denom = np.where(temp_denom <= 0, 1e-5, temp_denom)\n",
    "            P_hat_new = temp_num / temp_denom\n",
    "            error_pi, error_P = np.linalg.norm(pi_hat_new - pi_hat), np.linalg.norm(P_hat_new - P_hat)\n",
    "            pi_hat, P_hat = pi_hat_new, P_hat_new\n",
    "            if max(error_pi, error_P) < tol:\n",
    "                break\n",
    "            inner_iter += 1\n",
    "        \n",
    "        # eq 2.4\n",
    "        P_hat = np.where(P_hat<=0, 1e-5, P_hat)\n",
    "        P_hat = np.where(P_hat>=1, 1 - 1e-5, P_hat)\n",
    "        P_hat = P_hat.transpose((0, 2, 1))\n",
    "        temp = tau_mat[np.newaxis, :, np.newaxis, np.newaxis, :] * (scbm[:, :, :, np.newaxis, np.newaxis] * np.log(P_hat[:, np.newaxis, np.newaxis, :, :]) + (1 - scbm[:, :, :, np.newaxis, np.newaxis]) * np.log(1 - P_hat[:, np.newaxis, np.newaxis, :, :]))\n",
    "        clusters_est_new = np.argmax(np.sum(temp, axis=(0, 1, 4)), axis=1)\n",
    "        error_cluster = np.count_nonzero(clusters_est_new - clusters_est)\n",
    "        clusters_est = clusters_est_new\n",
    "        if  error_cluster <= 0:\n",
    "            break\n",
    "\n",
    "    return clusters_est\n",
    "\n",
    "\n",
    "def min_mis_error(true_label, kmeans_labels, K_clusters):\n",
    "    \"\"\"optimal permutation\"\"\"\n",
    "    kmeans_labels_p = deepcopy(kmeans_labels)\n",
    "    location = []\n",
    "    for i in range(K_clusters):\n",
    "        location.append(np.where(kmeans_labels_p == i))\n",
    "    \n",
    "    error_min = 1\n",
    "    for cp in permutations(range(K_clusters), K_clusters):\n",
    "        for j, r in enumerate(cp):\n",
    "            kmeans_labels_p[location[j]] = r\n",
    "        error = np.sum(kmeans_labels_p != true_label) / true_label.shape[0]\n",
    "        if error <= error_min:\n",
    "            error_min = error\n",
    "            best_p = cp\n",
    "    \n",
    "    for j, r in enumerate(best_p):\n",
    "        kmeans_labels_p[location[j]] = r\n",
    "        \n",
    "    return error_min    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y = Z\n",
    "\n",
    "### The row and column membership matrices are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_n_couple(B_1, B_2, layer, n_nodes, K, K_sum, K_clusters, density, n_trials=100, row=True, initial=\"random\"):\n",
    "    n_nodes = np.atleast_1d(n_nodes)\n",
    "    mis_errors = np.zeros((3, n_trials, n_nodes.shape[0])) #methods = [\"PL\", \"PPL\", \"dsog\"]\n",
    "    \n",
    "    for j in range(n_nodes.shape[0]):\n",
    "        size_communities = np.array([[0.33, 0.33, 0.34], [0.33, 0.33, 0.34]]) * n_nodes[j]\n",
    "        size_communities = size_communities.astype(int)\n",
    "        num_communities = [3, 3]\n",
    "        true_row_label = np.random.choice(np.repeat(range(num_communities[0]), size_communities[0]), replace=False, size=n_nodes[j])\n",
    "        true_column_label = true_row_label\n",
    "        link_matrices = np.concatenate((np.tile(B_1, (int(layer/2), 1, 1)), np.tile(B_2, (int(layer/2) + layer % 2, 1, 1))))\n",
    "\n",
    "        if row:\n",
    "            true_label = true_row_label\n",
    "        else:\n",
    "            true_label = true_column_label\n",
    "\n",
    "        k_means = KMeans(init=\"k-means++\", n_clusters=K_clusters, n_init=n_nodes[j])\n",
    "\n",
    "        # initial value \n",
    "        scbm = ScBM_generator(true_row_label, true_column_label, link_matrices, density)\n",
    "        if initial == \"dsog\":\n",
    "            _, vs = k_eigenvectors(scbm, K, method=\"qsum\", row=row) # DSoG\n",
    "            k_means.fit(vs)\n",
    "            initial_value = k_means.labels_\n",
    "        elif initial == \"sum\":\n",
    "            vs = k_eigenvectors(scbm, K_sum, method=\"sum\", row=row) # Sum\n",
    "            k_means.fit(vs)\n",
    "            initial_value = k_means.labels_\n",
    "        else:\n",
    "            initial_value = np.random.choice(K_clusters, n_nodes[j])\n",
    "\n",
    "\n",
    "        for i in range(n_trials):\n",
    "            scbm = ScBM_generator(true_row_label, true_column_label, link_matrices, density)\n",
    "            print(\"#Nodes: %s,  Trial: %s;    \" %(n_nodes[j], i+1))\n",
    "            _, vs_debias = k_eigenvectors(scbm, K, method=\"qsum\", row=row)\n",
    "            k_means.fit(vs_debias)\n",
    "            mis_errors[2, i, j] =min_mis_error(true_label, k_means.labels_, k_means.n_clusters)\n",
    "\n",
    "            pl_label = PL(scbm, K_clusters, initial_value, row=row)  \n",
    "            mis_errors[0, i, j] = min_mis_error(true_label, pl_label, K_clusters)\n",
    "\n",
    "            ppl_label = PPL(scbm, K_clusters, initial_value, row=row) \n",
    "            mis_errors[1, i, j] = min_mis_error(true_label, ppl_label, K_clusters)\n",
    "\n",
    "    return mis_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.array([[1/2, 1/2, -np.sqrt(2)/2], [1/2, 1/2, np.sqrt(2)/2], [np.sqrt(2)/2, -np.sqrt(2)/2, 0]])\n",
    "V = np.array([[np.sqrt(2)/2, -np.sqrt(2)/2, 0], [1/2, 1/2, -np.sqrt(2)/2], [1/2, 1/2, np.sqrt(2)/2]])\n",
    "Lambda1 = np.diag([1.5, 0.2, 0.4])\n",
    "Lambda2 = np.diag([1.5, 0.2, -0.4])\n",
    "B_1 = U@Lambda1@V.T\n",
    "B_2 = U@Lambda2@V.T\n",
    "\n",
    "K_clusters = 3\n",
    "K = 3 # K leading eigenvectors\n",
    "K_sum = 2\n",
    "\n",
    "n_nodes = np.arange(300, 1501, 100)\n",
    "# # random initial value\n",
    "# # row community reconstruction\n",
    "# np.random.seed(2024)\n",
    "# row_10l_couple_random = repeat_n_couple(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"random\")\n",
    "# # column community reconstruction\n",
    "# np.random.seed(2025)\n",
    "# column_10l_couple_random = repeat_n_couple(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"random\", row=False)\n",
    "\n",
    "# # initial value Sum\n",
    "# # row community reconstruction\n",
    "# np.random.seed(2024)\n",
    "# row_10l_couple_sum = repeat_n_couple(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"sum\")\n",
    "# # column community reconstruction\n",
    "# np.random.seed(2025)\n",
    "# column_10l_couple_sum = repeat_n_couple(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"sum\", row=False)\n",
    "\n",
    "# initial value DSoG\n",
    "# row community reconstruction\n",
    "np.random.seed(2024)\n",
    "row_10l_couple_dsog = repeat_n_couple(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"dsog\")\n",
    "# column community reconstruction\n",
    "np.random.seed(2025)\n",
    "column_10l_couple_dsog = repeat_n_couple(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"dsog\", row=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "font = {\"family\": \"Times New Roman\", \"weight\": \"normal\", \"size\": 13}    \n",
    "color_list = [\"#534439\", \"#9A5F30\", \"#62B17C\"]\n",
    "\n",
    "def plot_mis(mis_errors, methods_list=[\"ML-PL\", \"ML-PPL\", \"DSoG\"]):\n",
    "    \"\"\"mis_errors is a (n_methodes, n_trials, n_densities) ndarray\"\"\"\n",
    "    plt.figure(figsize=(6,3.6))\n",
    "    sns.lineplot(pd.DataFrame(mis_errors.mean(axis=1).T, n_nodes, methods_list), \n",
    "                 markers=[\"o\", \"X\", \"p\"], dashes=False, palette=color_list, linewidth=2)\n",
    "    plt.xlabel(\"The number of nodes n\", font)\n",
    "    plt.ylabel(\"Misclassification rate\", font)\n",
    "    plt.legend(ncol=3, loc=1, prop=font)\n",
    "    plt.ylim(-0.015, 0.38)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_mis(row_10l_couple_random)\n",
    "# plot_mis(column_10l_couple_random)\n",
    "# plot_mis(row_10l_couple_sum)\n",
    "# plot_mis(column_10l_couple_sum)\n",
    "plot_mis(row_10l_couple_dsog)\n",
    "plot_mis(column_10l_couple_dsog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y != Z\n",
    "\n",
    "### The row and column membership matrices are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_n(B_1, B_2, layer, n_nodes, K, K_sum, K_clusters, density, n_trials=100, row=True, initial=\"random\"):\n",
    "    n_nodes = np.atleast_1d(n_nodes)\n",
    "    mis_errors = np.zeros((3, n_trials, n_nodes.shape[0])) #methods = [\"PL\", \"PPL\", \"dsog\"]\n",
    "    \n",
    "    for j in range(n_nodes.shape[0]):\n",
    "        size_communities = np.array([[0.33, 0.33, 0.34], [0.34, 0.33, 0.33]]) * n_nodes[j]\n",
    "        size_communities = size_communities.astype(int)\n",
    "        num_communities = [3, 3]\n",
    "        true_row_label = np.random.choice(np.repeat(range(num_communities[0]), size_communities[0]), replace=False, size=n_nodes[j])\n",
    "        true_column_label = np.random.choice(np.repeat(range(num_communities[1]), size_communities[1]), replace=False, size=n_nodes[j])\n",
    "        link_matrices = np.concatenate((np.tile(B_1, (int(layer/2), 1, 1)), np.tile(B_2, (int(layer/2) + layer % 2, 1, 1))))\n",
    "\n",
    "        if row:\n",
    "            true_label = true_row_label\n",
    "        else:\n",
    "            true_label = true_column_label\n",
    "\n",
    "        k_means = KMeans(init=\"k-means++\", n_clusters=K_clusters, n_init=n_nodes[j])\n",
    "        \n",
    "        # initial value \n",
    "        scbm = ScBM_generator(true_row_label, true_column_label, link_matrices, density)\n",
    "        if initial == \"dsog\":\n",
    "            _, vs = k_eigenvectors(scbm, K, method=\"qsum\", row=row) # DSoG\n",
    "        else:\n",
    "            vs = k_eigenvectors(scbm, K_sum, method=\"sum\", row=row) # Sum\n",
    "        k_means.fit(vs)\n",
    "        initial_value = k_means.labels_\n",
    "\n",
    "\n",
    "        for i in range(n_trials):\n",
    "            scbm = ScBM_generator(true_row_label, true_column_label, link_matrices, density)\n",
    "            print(\"#Nodes: %s,  Trial: %s;    \" %(n_nodes[j], i+1))\n",
    "            _, vs_debias = k_eigenvectors(scbm, K, method=\"qsum\", row=row)\n",
    "            k_means.fit(vs_debias)\n",
    "            mis_errors[2, i, j] =min_mis_error(true_label, k_means.labels_, k_means.n_clusters)\n",
    "\n",
    "            pl_label = PL(scbm, K_clusters, initial_value, row=row)\n",
    "            mis_errors[0, i, j] = min_mis_error(true_label, pl_label, K_clusters)\n",
    "\n",
    "            ppl_label = PPL(scbm, K_clusters, initial_value, row=row)\n",
    "            mis_errors[1, i, j] = min_mis_error(true_label, ppl_label, K_clusters)\n",
    "\n",
    "    return mis_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.array([[1/2, 1/2, -np.sqrt(2)/2], [1/2, 1/2, np.sqrt(2)/2], [np.sqrt(2)/2, -np.sqrt(2)/2, 0]])\n",
    "V = np.array([[np.sqrt(2)/2, -np.sqrt(2)/2, 0], [1/2, 1/2, -np.sqrt(2)/2], [1/2, 1/2, np.sqrt(2)/2]])\n",
    "Lambda1 = np.diag([1.5, 0.2, 0.4])\n",
    "Lambda2 = np.diag([1.5, 0.2, -0.4])\n",
    "B_1 = U@Lambda1@V.T\n",
    "B_2 = U@Lambda2@V.T\n",
    "K_clusters = 3\n",
    "K = 3 # K leading eigenvectors\n",
    "K_sum = 2\n",
    "\n",
    "n_nodes = np.arange(300, 1501, 100)\n",
    "# # random initial value\n",
    "# # row community reconstruction\n",
    "# np.random.seed(2024)\n",
    "# row_10l_random = repeat_n(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"random\")\n",
    "# # column community reconstruction\n",
    "# np.random.seed(2025)\n",
    "# column_10l_random = repeat_n(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"random\", row=False)\n",
    "\n",
    "# # initial value Sum\n",
    "# # row community reconstruction\n",
    "# np.random.seed(2024)\n",
    "# row_10l_sum = repeat_n(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"sum\")\n",
    "# # column community reconstruction\n",
    "# np.random.seed(2025)\n",
    "# column_10l_sum = repeat_n(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"sum\", row=False)\n",
    "\n",
    "# initial value DSoG\n",
    "# row community reconstruction\n",
    "np.random.seed(2024)\n",
    "row_10l_dsog = repeat_n(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"dsog\")\n",
    "# column community reconstruction\n",
    "np.random.seed(2025)\n",
    "column_10l_dsog = repeat_n(B_1, B_2, 10, n_nodes, K, K_sum, K_clusters, 0.1, n_trials=50, initial=\"dsog\", row=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "font = {\"family\": \"Times New Roman\", \"weight\": \"normal\", \"size\": 13}    \n",
    "color_list = [\"#534439\", \"#9A5F30\", \"#62B17C\"]\n",
    "\n",
    "def plot_mis(mis_errors, methods_list=[\"ML-PL\", \"ML-PPL\", \"DSoG\"]):\n",
    "    \"\"\"mis_errors is a (n_methodes, n_trials, n_densities) ndarray\"\"\"\n",
    "    plt.figure(figsize=(6,3.6))\n",
    "    sns.lineplot(pd.DataFrame(mis_errors.mean(axis=1).T, n_nodes, methods_list), \n",
    "                 markers=[\"o\", \"X\", \"p\"], dashes=False, palette=color_list, linewidth=2)\n",
    "    plt.xlabel(\"The number of nodes n\", font)\n",
    "    plt.ylabel(\"Misclassification rate\", font)\n",
    "    plt.legend(ncol=3, loc=1, prop=font)\n",
    "    plt.ylim(-0.015, 0.42)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_mis(row_10l_random)\n",
    "# plot_mis(column_10l_random)\n",
    "# plot_mis(row_10l_sum)\n",
    "# plot_mis(column_10l_sum)\n",
    "plot_mis(row_10l_dsog)\n",
    "plot_mis(column_10l_dsog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b41e27ad085b19821bb085b48e73502d65bca19675aa415831fbb34e2d365fd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
